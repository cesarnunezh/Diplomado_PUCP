{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb92e597586c04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trabajo 2 - Big Data\n",
    "<b>Integrantes:<b/> \n",
    "- Gabriela Calvo\n",
    "- Mauricio Ibáñez\n",
    "- César Núñez\n",
    "- Rodrigo Soto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923fdb44aa02dde6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5999c73af007fae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. Explique, de manera sencilla, cómo el algoritmo de Dask se relaciona con el método de Foster. Agregue ejemplos. (150 palabras, 1 puntos) \n",
    "El Dask, recoge el concepto de la metodología de Foster para la implementación de la paralelización de tareas, y además los incorpora para su diseño y funcionamiento. Es especialmente útil en grandes volúmenes de datos que puedan ser distribuidos en tareas paralelizables, y así aprovechar las mismas en maximizar los recursos de cómputo, análisis de datos, modelos de machine learning, entre otras.\n",
    "Un ejemplo sería, la evaluación del rendimiento escolar vinculado a la infraestructura educativa, para evaluar este impacto requeriría que se abarque información respecto al rendimiento escolar y el estado de la infraestructura educativa; en distritos, provincias o regiones, dependiendo la precisión con que se quiere medir. En este caso, el Dask podría paralelizar la recopilación de datos y el análisis de los mismos, aprovechando el agrupamiento de tareas. Esto, a su vez, respaldaría la toma de decisiones educativas, entre ellas, la asignación de recursos para intervenciones en infraestructura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ca0b68115008c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. No todo se debe paralelizar. ¿Bajo qué circuntancias la paralelización podría ser ineficiente? Provea al menos dos ejemplos. (150 palabras, 1 puntos)\n",
    "Podría ser ineficiente debido a la capacidad limitada de recursos en software y/o hardware del cpu y gpu, lo que podría generar cuellos de botella, en vez de acelerar los procesos y resultados. Asimismo, podría ser ineficiente en la compilación de un código o script, dado que en la mayoría de casos éste depende del resultado de lo anterior para que pueda continuar con el proceso. \n",
    "Por ejemplo, en el caso de modelos de churn, la paralización es ineficiente, toda vez que es necesario conocer el comportamiento de los clientes, es decir la secuencialidad de los eventos producidos para etiquetar a un cliente como “fuga” o “no fuga”, y posterior predicción. Otro ejemplo sería, en un modelo para la mejora del tráfico automovilístico en el Perú, dada la información en tiempo real y eventos de diferente naturaleza para optimizar el flujo vehicular, no es posible que este sea paralelizable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d035182e955d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. Revise el artículo de Desouza y Smith (2014) en Stanford Social Innovation Review y la presentación de Ng en el Data+AI Summit 2022. Elabore un comentario informado y crítico sobre “Good Data & Big Data”. ¿uno reemplazará al otro y por qué? ¿se pueden complementar y cómo? Agregue al menos dos ejemplos/ideas acordes a su argumento relacionados al caso peruano (400 palabras, 4 puntos). \n",
    "Respecto a la GoodData, se refiere a la calidad y confiabilidad de los datos, ya que estos serán apropiados para implementar un “modelo” vinculado principalmente a la IA; respecto al Big Data, se refiere a la cantidad, volumen y el recojo de los datos, ya sea en data estructurada o no estructurada, entre otros. Cabe precisar, que el GoodData enriquecerá al BigData, y son términos que no son independientes, ambos enfoques son esenciales para aprovechar e incrementar el valor de los datos, lo cual contribuiría en la planificación estratégica y son cruciales para garantizar el éxito en políticas públicas. Estos dos términos se complementarán al momento de elaborar un “modelo”, toda vez que si no se tienen datos adecuados, el resultado del “modelo” no será el óptimo; si se tiene la suficiente cantidad de datos los cuales son de calidad, los resultados que arroje el análisis de los mismos, servirán de base para tomar decisiones confiables e informadas. \n",
    "\n",
    "Por ejemplo, un problema de la gestión pública, está vinculada a las contrataciones públicas, precisamente en saldos de obra, toda vez que, contando con cantidad y calidad de los datos el cual está vinculado a los dos términos materia de análisis, se podrían generar modelos de ML y tomar acciones para prevenir la resolución de obras por diversos factores; es conocido que hay contratistas que se benefician de las obras, suscriben contratos, ejecutan la obra parcialmente y posteriormente no las culminan, lo que resulta en saldos de obra, generando perjuicios para el sector público y la población beneficiaria; posterior al saldo de obra, se elaborará nuevamente el expediente técnico y se convocará a proceso de selección, lo que generará que la obra en mención, sea construida años después de lo previsto. \n",
    "\n",
    "Otro ejemplo vinculado a las contrataciones públicas, es respecto a la ejecución de las obras; es fundamental contar con la información adecuada de la ejecución de las obras, respecto a los contratistas ejecutoras, el presupuesto adjudicado y el presupuesto con el cual culmina dicha obra, plazo inicial y final,  entre otros, toda vez que, algunos contratistas se aprovechan de diversos factores para generar mayores costos, que están vinculados con adicionales de obra y las ampliaciones de plazos, generando mayores ganancias para los contratistas; por tal motivo, es importante recopilar estos datos de manera adecuada a fin elaborar un modelo predictivo para detectar estos posibles casos y tomar acciones correctivas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726235b81a6645db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. Imagina que estás trabajando en un proyecto de análisis de datos para una empresa que maneja una gran cantidad de registros de ventas en línea. Explica cómo Dask podría aplicarse de manera específica para acelerar el procesamiento y análisis de estos registros. Proporciona un ejemplo detallado de cómo Dask podría utilizarse para realizar una tarea específica en este contexto y menciona las ventajas que ofrece Dask en términos de paralelización y escalabilidad en comparación con enfoques tradicionales. (300 palabras, 2 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e27395959585f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258dfb79d5c8b02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. (1 punto) Presentación y relevancia del problema de predicción que se desea realizar (por ejemplo, predecir la vulnerabilidad de los hogares en el Perú). Defina claramente qué datos utilizara, cuál es su variable target y cuáles sus predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77031a4b95ad05e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### 2. (1 puntos) Describa los pasos a realizar para su aplicación de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb58b11f0227ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### 3. (3 puntos) Describa cómo llevaría a cabo este ejercicio de manera paralelizada y compárelo a su aplicación serial. Como parte de esta descripción, incluir los siguientes aspectos:\n",
    "\n",
    "a. Explicar qué partes del ejercicio se harán de forma serial y por qué no paralelizo estas tareas.\n",
    "b. Para las tareas en paralelo, explique usando el método de Foster como se dan las etapas de partición, comunicación, aglomeración y mapeo (PCAM) para su aplicación.\n",
    "c. Discuta qué tipos de procesadores podría utilizar para cada parte. (No es necesario que utilice los GPU pese a que señale su mejor desempeño)\n",
    "d. Identificar los cuellos de botella del ejercicio y comente hasta qué punto la paralelización puede ayudar a resolverlos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f096579e6bcb025",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. Uso de DASK\n",
    "##### a. Ejercicio de ETL: Usar Dask Dataframes para cargar la(s) base(s) de datos que se utilizará(n) y presentar lo siguiente:\n",
    "\n",
    "- Creación de por lo menos dos variables \n",
    "- Por lo menos dos estadísticos descriptivos que vayan en línea con el tema y argumento. Explíquelos \n",
    "- Por lo menos dos gráficos que vayan en línea con el tema y argumento.\n",
    "\n",
    "Tanto los gráficos como los descriptivos deben estar en calidad para ser incluidos en un reporte final. Se descontarán puntos por presentación descuidada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb55ad90821e22b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(r'C:\\Users\\User\\Documents\\GitHub\\Diplomado_PUCP_trabajos\\Big Data\\Trabajo 2')\n",
    "\n",
    "ddf_2023 = dd.read_csv('brecha_educativa_jul2023.csv')\n",
    "ddf_2021 = dd.read_csv('brecha_educativa_jul2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9753d2153bc91403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T20:26:33.537150Z",
     "start_time": "2023-09-16T20:26:33.521513900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         int64\n",
       "cod_loc            int64\n",
       "region_loc        object\n",
       "provincia_loc     object\n",
       "distrito_loc      object\n",
       "                  ...   \n",
       "pred_prestado    float64\n",
       "pred_cedido      float64\n",
       "pred_otro        float64\n",
       "pred_total       float64\n",
       "albergado         object\n",
       "Length: 72, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2023.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8919f1f4a5b804e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T20:32:00.063694200Z",
     "start_time": "2023-09-16T20:32:00.062433900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddf_2021_final = ddf_2021.loc[:('cod_loc','grupo_prioridad')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b0f1ad95c9a0c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T20:32:57.758939900Z",
     "start_time": "2023-09-16T20:32:57.703911500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dytypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ddf_final \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mmerge(ddf_2023,ddf_2021_final, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcod_loc\u001b[39m\u001b[38;5;124m'\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mddf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdytypes\u001b[49m\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\core.py:4988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4986\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m   4987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dytypes'"
     ]
    }
   ],
   "source": [
    "ddf_final = dd.merge(ddf_2023,ddf_2021_final, on = 'cod_loc', how = 'left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
