{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uukJ7bZ2NcES"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el conjunto de datos Fashion MNIST\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Dividimos el conjunto de entrenamiento en entrenamiento y validación\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify=y_train, test_size=0.1)\n",
        "\n",
        "# Preprocesamiento de las imágenes\n",
        "x_train = np.expand_dims(x_train, axis=-1).astype(\"float32\")/255.0\n",
        "x_val = np.expand_dims(x_val, axis=-1).astype(\"float32\")/255.0\n",
        "x_test = np.expand_dims(x_test, axis=-1).astype(\"float32\")/255.0\n",
        "\n",
        "# Definimos el modelo de red neuronal\n",
        "model = Sequential(name=\"MyModel\")\n",
        "model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "model.add(Dense(100, activation=tf.nn.relu))\n",
        "model.add(Dense(100, activation=tf.nn.relu))\n",
        "model.add(Dense(100, activation=tf.nn.relu))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "# Configuración del modelo\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Callbacks para guardar el modelo y detener el entrenamiento\n",
        "mode_autosave = ModelCheckpoint(\"classification_model.h5\", mode=\"max\", save_best_only=True, monitor=\"val_accuracy\", verbose=1)\n",
        "early_stopping = EarlyStopping(patience=40, verbose=1, mode=\"auto\")\n",
        "callbacks = [mode_autosave, early_stopping]\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=200, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "# Cargamos los pesos del modelo con mejor desempeño en validación\n",
        "model.load_weights(\"classification_model.h5\")\n",
        "\n",
        "# Evaluación del modelo en los conjuntos de datos\n",
        "print(\"Train:\")\n",
        "scores_train = model.evaluate(x_train, y_train)\n",
        "print(\"Validation:\")\n",
        "scores_val = model.evaluate(x_val, y_val)\n",
        "print(\"Test:\")\n",
        "scores_test = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu2r4s1PNg4Y",
        "outputId": "65872574-5323-4d4b-8c7c-46a8fe55a2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.5076 - accuracy: 0.8189\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84600, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.5073 - accuracy: 0.8190 - val_loss: 0.4036 - val_accuracy: 0.8460\n",
            "Epoch 2/200\n",
            "  18/1688 [..............................] - ETA: 10s - loss: 0.4313 - accuracy: 0.8385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.8630\n",
            "Epoch 2: val_accuracy improved from 0.84600 to 0.85750, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3745 - accuracy: 0.8631 - val_loss: 0.3922 - val_accuracy: 0.8575\n",
            "Epoch 3/200\n",
            "1676/1688 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.8731\n",
            "Epoch 3: val_accuracy improved from 0.85750 to 0.88117, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3421 - accuracy: 0.8728 - val_loss: 0.3311 - val_accuracy: 0.8812\n",
            "Epoch 4/200\n",
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.8817\n",
            "Epoch 4: val_accuracy improved from 0.88117 to 0.88533, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.3200 - accuracy: 0.8816 - val_loss: 0.3163 - val_accuracy: 0.8853\n",
            "Epoch 5/200\n",
            "1686/1688 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8880\n",
            "Epoch 5: val_accuracy improved from 0.88533 to 0.88667, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3003 - accuracy: 0.8880 - val_loss: 0.3137 - val_accuracy: 0.8867\n",
            "Epoch 6/200\n",
            "1680/1688 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.8929\n",
            "Epoch 6: val_accuracy improved from 0.88667 to 0.89067, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2847 - accuracy: 0.8929 - val_loss: 0.2998 - val_accuracy: 0.8907\n",
            "Epoch 7/200\n",
            "1677/1688 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.8957\n",
            "Epoch 7: val_accuracy did not improve from 0.89067\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2749 - accuracy: 0.8956 - val_loss: 0.3239 - val_accuracy: 0.8877\n",
            "Epoch 8/200\n",
            "1676/1688 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9014\n",
            "Epoch 8: val_accuracy improved from 0.89067 to 0.89633, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.2634 - accuracy: 0.9016 - val_loss: 0.2881 - val_accuracy: 0.8963\n",
            "Epoch 9/200\n",
            "1678/1688 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9055\n",
            "Epoch 9: val_accuracy did not improve from 0.89633\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2532 - accuracy: 0.9056 - val_loss: 0.3128 - val_accuracy: 0.8915\n",
            "Epoch 10/200\n",
            "1682/1688 [============================>.] - ETA: 0s - loss: 0.2435 - accuracy: 0.9076\n",
            "Epoch 10: val_accuracy did not improve from 0.89633\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2434 - accuracy: 0.9076 - val_loss: 0.2995 - val_accuracy: 0.8945\n",
            "Epoch 11/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9112\n",
            "Epoch 11: val_accuracy did not improve from 0.89633\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2352 - accuracy: 0.9112 - val_loss: 0.3248 - val_accuracy: 0.8912\n",
            "Epoch 12/200\n",
            "1675/1688 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9137\n",
            "Epoch 12: val_accuracy improved from 0.89633 to 0.89683, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2295 - accuracy: 0.9138 - val_loss: 0.2878 - val_accuracy: 0.8968\n",
            "Epoch 13/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.2197 - accuracy: 0.9167\n",
            "Epoch 13: val_accuracy did not improve from 0.89683\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2197 - accuracy: 0.9167 - val_loss: 0.3198 - val_accuracy: 0.8872\n",
            "Epoch 14/200\n",
            "1688/1688 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9190\n",
            "Epoch 14: val_accuracy did not improve from 0.89683\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2139 - accuracy: 0.9190 - val_loss: 0.3188 - val_accuracy: 0.8945\n",
            "Epoch 15/200\n",
            "1680/1688 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9207\n",
            "Epoch 15: val_accuracy did not improve from 0.89683\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2088 - accuracy: 0.9206 - val_loss: 0.3349 - val_accuracy: 0.8942\n",
            "Epoch 16/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9218\n",
            "Epoch 16: val_accuracy did not improve from 0.89683\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2022 - accuracy: 0.9218 - val_loss: 0.3169 - val_accuracy: 0.8932\n",
            "Epoch 17/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9242\n",
            "Epoch 17: val_accuracy improved from 0.89683 to 0.89700, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1975 - accuracy: 0.9241 - val_loss: 0.3182 - val_accuracy: 0.8970\n",
            "Epoch 18/200\n",
            "1682/1688 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9261\n",
            "Epoch 18: val_accuracy did not improve from 0.89700\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1932 - accuracy: 0.9262 - val_loss: 0.3283 - val_accuracy: 0.8898\n",
            "Epoch 19/200\n",
            "1673/1688 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9288\n",
            "Epoch 19: val_accuracy did not improve from 0.89700\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1832 - accuracy: 0.9287 - val_loss: 0.3148 - val_accuracy: 0.8967\n",
            "Epoch 20/200\n",
            "1676/1688 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9302\n",
            "Epoch 20: val_accuracy improved from 0.89700 to 0.89833, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1799 - accuracy: 0.9301 - val_loss: 0.3312 - val_accuracy: 0.8983\n",
            "Epoch 21/200\n",
            "1681/1688 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9319\n",
            "Epoch 21: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1747 - accuracy: 0.9319 - val_loss: 0.3402 - val_accuracy: 0.8922\n",
            "Epoch 22/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9331\n",
            "Epoch 22: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1734 - accuracy: 0.9330 - val_loss: 0.3894 - val_accuracy: 0.8915\n",
            "Epoch 23/200\n",
            "1679/1688 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9349\n",
            "Epoch 23: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1670 - accuracy: 0.9349 - val_loss: 0.4072 - val_accuracy: 0.8830\n",
            "Epoch 24/200\n",
            "1687/1688 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9369\n",
            "Epoch 24: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1617 - accuracy: 0.9369 - val_loss: 0.4281 - val_accuracy: 0.8907\n",
            "Epoch 25/200\n",
            "1688/1688 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9375\n",
            "Epoch 25: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1632 - accuracy: 0.9375 - val_loss: 0.3477 - val_accuracy: 0.8952\n",
            "Epoch 26/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9375\n",
            "Epoch 26: val_accuracy did not improve from 0.89833\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1581 - accuracy: 0.9374 - val_loss: 0.3788 - val_accuracy: 0.8890\n",
            "Epoch 27/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9414\n",
            "Epoch 27: val_accuracy improved from 0.89833 to 0.89883, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1507 - accuracy: 0.9414 - val_loss: 0.3822 - val_accuracy: 0.8988\n",
            "Epoch 28/200\n",
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9435\n",
            "Epoch 28: val_accuracy did not improve from 0.89883\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1480 - accuracy: 0.9435 - val_loss: 0.3668 - val_accuracy: 0.8970\n",
            "Epoch 29/200\n",
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9430\n",
            "Epoch 29: val_accuracy did not improve from 0.89883\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1490 - accuracy: 0.9431 - val_loss: 0.3824 - val_accuracy: 0.8890\n",
            "Epoch 30/200\n",
            "1682/1688 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9455\n",
            "Epoch 30: val_accuracy improved from 0.89883 to 0.90183, saving model to classification_model.h5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1431 - accuracy: 0.9455 - val_loss: 0.4058 - val_accuracy: 0.9018\n",
            "Epoch 31/200\n",
            "1675/1688 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9451\n",
            "Epoch 31: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1402 - accuracy: 0.9451 - val_loss: 0.4014 - val_accuracy: 0.9012\n",
            "Epoch 32/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9471\n",
            "Epoch 32: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1373 - accuracy: 0.9471 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
            "Epoch 33/200\n",
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9468\n",
            "Epoch 33: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1361 - accuracy: 0.9468 - val_loss: 0.3866 - val_accuracy: 0.8987\n",
            "Epoch 34/200\n",
            "1679/1688 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9497\n",
            "Epoch 34: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1325 - accuracy: 0.9498 - val_loss: 0.3890 - val_accuracy: 0.9002\n",
            "Epoch 35/200\n",
            "1678/1688 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9522\n",
            "Epoch 35: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1266 - accuracy: 0.9522 - val_loss: 0.4330 - val_accuracy: 0.8930\n",
            "Epoch 36/200\n",
            "1687/1688 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9498\n",
            "Epoch 36: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1290 - accuracy: 0.9498 - val_loss: 0.4181 - val_accuracy: 0.8967\n",
            "Epoch 37/200\n",
            "1688/1688 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9502\n",
            "Epoch 37: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1272 - accuracy: 0.9502 - val_loss: 0.4248 - val_accuracy: 0.8992\n",
            "Epoch 38/200\n",
            "1679/1688 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9529\n",
            "Epoch 38: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1218 - accuracy: 0.9529 - val_loss: 0.4299 - val_accuracy: 0.8947\n",
            "Epoch 39/200\n",
            "1678/1688 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9516\n",
            "Epoch 39: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1225 - accuracy: 0.9515 - val_loss: 0.4783 - val_accuracy: 0.8980\n",
            "Epoch 40/200\n",
            "1677/1688 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.9536\n",
            "Epoch 40: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1222 - accuracy: 0.9536 - val_loss: 0.4562 - val_accuracy: 0.8950\n",
            "Epoch 41/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9549\n",
            "Epoch 41: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1169 - accuracy: 0.9549 - val_loss: 0.4842 - val_accuracy: 0.8980\n",
            "Epoch 42/200\n",
            "1682/1688 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9549\n",
            "Epoch 42: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1148 - accuracy: 0.9550 - val_loss: 0.4569 - val_accuracy: 0.8990\n",
            "Epoch 43/200\n",
            "1686/1688 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9549\n",
            "Epoch 43: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1158 - accuracy: 0.9549 - val_loss: 0.4861 - val_accuracy: 0.8930\n",
            "Epoch 44/200\n",
            "1676/1688 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9569\n",
            "Epoch 44: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1091 - accuracy: 0.9568 - val_loss: 0.4617 - val_accuracy: 0.8950\n",
            "Epoch 45/200\n",
            "1675/1688 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9576\n",
            "Epoch 45: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1092 - accuracy: 0.9575 - val_loss: 0.4682 - val_accuracy: 0.8980\n",
            "Epoch 46/200\n",
            "1682/1688 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9593\n",
            "Epoch 46: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1060 - accuracy: 0.9593 - val_loss: 0.4940 - val_accuracy: 0.8923\n",
            "Epoch 47/200\n",
            "1685/1688 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9578\n",
            "Epoch 47: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1113 - accuracy: 0.9579 - val_loss: 0.4771 - val_accuracy: 0.8918\n",
            "Epoch 48/200\n",
            "1679/1688 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.9610\n",
            "Epoch 48: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9611 - val_loss: 0.5604 - val_accuracy: 0.8933\n",
            "Epoch 49/200\n",
            "1683/1688 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9612\n",
            "Epoch 49: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.4806 - val_accuracy: 0.8900\n",
            "Epoch 50/200\n",
            "1687/1688 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9594\n",
            "Epoch 50: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1059 - accuracy: 0.9594 - val_loss: 0.5197 - val_accuracy: 0.8972\n",
            "Epoch 51/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9612\n",
            "Epoch 51: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1006 - accuracy: 0.9611 - val_loss: 0.5193 - val_accuracy: 0.8963\n",
            "Epoch 52/200\n",
            "1684/1688 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9629\n",
            "Epoch 52: val_accuracy did not improve from 0.90183\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0975 - accuracy: 0.9628 - val_loss: 0.5708 - val_accuracy: 0.8937\n",
            "Epoch 52: early stopping\n",
            "Train:\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1222 - accuracy: 0.9527\n",
            "Validation:\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.9018\n",
            "Test:\n",
            " 87/313 [=======>......................] - ETA: 0s - loss: 0.4154 - accuracy: 0.8933"
          ]
        }
      ]
    }
  ]
}